[BASE]
base_io_directory = ./
base_directory = ./
root_models_prefix = input/models/
root_outputs_prefix = output/models/
model_name = v1-5-pruned-emaonly
clip_model_name = vit-large-patch14
checkpoint = v1-5-pruned-emaonly.safetensors

[DIRS]
root_models_dir = ./input/models/
root_outputs_dir = ./output/models/
sd_default_model_dir = ./input/models/v1-5-pruned-emaonly
clip_models_dir = ./input/models/clip
text_embedder_dir = ./input/models/clip\text_embedder/

[PATHS]
checkpoint_path = ./input/models/v1-5-pruned-emaonly.safetensors
text_embedder_path = ./input/models/clip\text_embedder/text_embedder.safetensors
tokenizer_path = ./input/models/clip\text_embedder/tokenizer/
text_model_path = ./input/models/clip\text_embedder/vit-large-patch14
image_processor_path = ./input/models/clip\clip_image_encoder/image_processor.ckpt
clip_model_path = ./input/models/clip\clip_image_encoder/clip_model.ckpt
image_encoder_path = ./input/models/clip\clip_image_encoder/clip_image_encoder.ckpt
unet_path = ./input/models/v1-5-pruned-emaonly\unet.safetensors
autoencoder_path = ./input/models/v1-5-pruned-emaonly\autoencoder.safetensors
encoder_path = ./input/models/v1-5-pruned-emaonly\encoder.safetensors
decoder_path = ./input/models/v1-5-pruned-emaonly\decoder.safetensors
latent_diffusion_path = ./input/models/v1-5-pruned-emaonly\latent_diffusion.safetensors

