[BASE]
base_io_directory = ./
base_directory = ./
root_models_prefix = input/models/
root_outputs_prefix = output/models/
model_name = v1-5-pruned-emaonly
clip_model_name = vit-large-patch14
checkpoint = v1-5-pruned-emaonly.safetensors

[ROOT_DIRS]
root_models_dir = ./input/models/
root_outputs_dir = ./output/models/

[MODELS_DIRS]
sd_default_model_dir = ./input/models/v1-5-pruned-emaonly
clip_models_dir = ./input/models/clip

[SUBMODELS_DIRS]
text_embedder_dir = ./input/models/clip\text_embedder
image_encoder_dir = ./input/models/clip\image_encoder

[STABLE_DIFFUSION_PATHS]
checkpoint_path = ./input/models/v1-5-pruned-emaonly.safetensors
text_embedder_path = ./input/models/clip\text_embedder.safetensors
unet_path = ./input/models/v1-5-pruned-emaonly\unet.safetensors
autoencoder_path = ./input/models/v1-5-pruned-emaonly\autoencoder.safetensors
latent_diffusion_path = ./input/models/v1-5-pruned-emaonly\latent_diffusion.safetensors

[CLIP_PATHS]
image_processor_path = ./input/models/clip\image_encoder\image_processor.ckpt
clip_model_path = ./input/models/clip\image_encoder\clip_model.ckpt
image_encoder_path = ./input/models/clip\image_encoder\clip_image_encoder.ckpt
tokenizer_path = ./input/models/clip\text_embedder\tokenizer
text_model_path = ./input/models/clip\text_embedder\vit-large-patch14

