{
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "35bb3c45621b4fe3b3e991532d65d1b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76e42174ce1148649f569da7fdc454ef",
       "IPY_MODEL_9da8a9890ae34acd85e3322cb7e1879d",
       "IPY_MODEL_489eb1494d0841f5935e749061943405"
      ],
      "layout": "IPY_MODEL_6ff8e29f3ce74cc4aa499b0343c33461"
     }
    },
    "76e42174ce1148649f569da7fdc454ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52f9c152e30344a88e95c454b91a0e09",
      "placeholder": "​",
      "style": "IPY_MODEL_7b9dad6af99e4af9bdee1964d8672b00",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "9da8a9890ae34acd85e3322cb7e1879d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a7d01bab6164bfba8078ae217e0f601",
      "max": 961143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_585be3ffc10b4e29a46e00e91cffa9a1",
      "value": 961143
     }
    },
    "489eb1494d0841f5935e749061943405": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad3c6a5b16e74f9fa42658af767c5381",
      "placeholder": "​",
      "style": "IPY_MODEL_c9f1bf9cad794c0aa1985de2ceb0b0a6",
      "value": " 961k/961k [00:00&lt;00:00, 2.27MB/s]"
     }
    },
    "6ff8e29f3ce74cc4aa499b0343c33461": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52f9c152e30344a88e95c454b91a0e09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b9dad6af99e4af9bdee1964d8672b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a7d01bab6164bfba8078ae217e0f601": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "585be3ffc10b4e29a46e00e91cffa9a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad3c6a5b16e74f9fa42658af767c5381": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9f1bf9cad794c0aa1985de2ceb0b0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a278ebcc75b4f2fb9c44fc5616f0655": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_65681fd618634daa9981d5fbd423f5a0",
       "IPY_MODEL_3c2d584c22f14c06aaa06e542816cdea",
       "IPY_MODEL_69feb2189cc444249e9ed13cbd2603f6"
      ],
      "layout": "IPY_MODEL_28363e88abdb4333aefa4b76f660b69d"
     }
    },
    "65681fd618634daa9981d5fbd423f5a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ece614aa62b84c4eabd66efeb179ba00",
      "placeholder": "​",
      "style": "IPY_MODEL_df34c40d2a95440d9422b25d2710367d",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "3c2d584c22f14c06aaa06e542816cdea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02be864ed2fb4ce59d454e8e200f496e",
      "max": 524619,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd65dc920cb74cb4ae0775457d56bd4e",
      "value": 524619
     }
    },
    "69feb2189cc444249e9ed13cbd2603f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_deb11b201cbe4fde96c50448fcca96b9",
      "placeholder": "​",
      "style": "IPY_MODEL_19dfd19815484d53b09e73158ff7657b",
      "value": " 525k/525k [00:00&lt;00:00, 796kB/s]"
     }
    },
    "28363e88abdb4333aefa4b76f660b69d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ece614aa62b84c4eabd66efeb179ba00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df34c40d2a95440d9422b25d2710367d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02be864ed2fb4ce59d454e8e200f496e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd65dc920cb74cb4ae0775457d56bd4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "deb11b201cbe4fde96c50448fcca96b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19dfd19815484d53b09e73158ff7657b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "443a0558a9534b7295548bbe69070ff6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_967f2c42193c499ca18d644d0598b4c7",
       "IPY_MODEL_9bb488f5d9ee4c448da77e8b865ced5b",
       "IPY_MODEL_aac69752985c41309025a897cc3726f0"
      ],
      "layout": "IPY_MODEL_c334ed6114d5480caaef430ce31d557f"
     }
    },
    "967f2c42193c499ca18d644d0598b4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_914e18d4c9ec49f6bad984d89d0466d4",
      "placeholder": "​",
      "style": "IPY_MODEL_1429f8e001c043d48ded3d57b911f39b",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "9bb488f5d9ee4c448da77e8b865ced5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6645620b75fa4eeeb18eaf378042a627",
      "max": 389,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f2b4416f69b47f39871de6d894f47f6",
      "value": 389
     }
    },
    "aac69752985c41309025a897cc3726f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a727167a830f4b07b8b9e25bb5911069",
      "placeholder": "​",
      "style": "IPY_MODEL_197f71329bae49fc857cf9fba7b966ea",
      "value": " 389/389 [00:00&lt;00:00, 18.1kB/s]"
     }
    },
    "c334ed6114d5480caaef430ce31d557f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "914e18d4c9ec49f6bad984d89d0466d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1429f8e001c043d48ded3d57b911f39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6645620b75fa4eeeb18eaf378042a627": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f2b4416f69b47f39871de6d894f47f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a727167a830f4b07b8b9e25bb5911069": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "197f71329bae49fc857cf9fba7b966ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bfb796975fe43c3a4ff38a43dfffa15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0aaa27cb292c414fb9999ae6f3c430e0",
       "IPY_MODEL_afe6358503eb49a6a68cba812c779f9d",
       "IPY_MODEL_78fe3dc25b8d4d82934eb038c1f1c8c1"
      ],
      "layout": "IPY_MODEL_de1a6a29cee54ecbbfb8c45d917b714d"
     }
    },
    "0aaa27cb292c414fb9999ae6f3c430e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28606f18cfc64915b35fce34fa3e7802",
      "placeholder": "​",
      "style": "IPY_MODEL_b9a23c35e15d4be8ba27704873a4acb7",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "afe6358503eb49a6a68cba812c779f9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_629a3159f2cd4d87bcd4089e97af5e55",
      "max": 905,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85f7ddc1b32a4982a5e7d932b8d42c7b",
      "value": 905
     }
    },
    "78fe3dc25b8d4d82934eb038c1f1c8c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3315216024c84e7f811e62eb75dba07f",
      "placeholder": "​",
      "style": "IPY_MODEL_1a71866403fe4da4b93210e237d26b7e",
      "value": " 905/905 [00:00&lt;00:00, 20.3kB/s]"
     }
    },
    "de1a6a29cee54ecbbfb8c45d917b714d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28606f18cfc64915b35fce34fa3e7802": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9a23c35e15d4be8ba27704873a4acb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "629a3159f2cd4d87bcd4089e97af5e55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f7ddc1b32a4982a5e7d932b8d42c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3315216024c84e7f811e62eb75dba07f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a71866403fe4da4b93210e237d26b7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25d4e2a9fcf2431ba1341c55d2f4144d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b83beeea1244f5caa4fb129d24c223e",
       "IPY_MODEL_b123a76a5926475f8009b74201ca7f45",
       "IPY_MODEL_59154af5d9824f44a3dc5a25bb2ce745"
      ],
      "layout": "IPY_MODEL_9b7e5d7183464f06bff392c9477c236b"
     }
    },
    "6b83beeea1244f5caa4fb129d24c223e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f90762beb7e4b9d89508e8978aee4b8",
      "placeholder": "​",
      "style": "IPY_MODEL_c72cc1dedd7b4c04bc151223b534c3b4",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "b123a76a5926475f8009b74201ca7f45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3d81a1bb9f646ed810266cbe8a4a7af",
      "max": 4519,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59d5b5fcda0b43959b6dc4273519b5cc",
      "value": 4519
     }
    },
    "59154af5d9824f44a3dc5a25bb2ce745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6e6a5253ea84251831ad8fd46ccdd34",
      "placeholder": "​",
      "style": "IPY_MODEL_0b62c72b52f24b418d4e8175cf081513",
      "value": " 4.52k/4.52k [00:00&lt;00:00, 113kB/s]"
     }
    },
    "9b7e5d7183464f06bff392c9477c236b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f90762beb7e4b9d89508e8978aee4b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c72cc1dedd7b4c04bc151223b534c3b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3d81a1bb9f646ed810266cbe8a4a7af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59d5b5fcda0b43959b6dc4273519b5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6e6a5253ea84251831ad8fd46ccdd34": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b62c72b52f24b418d4e8175cf081513": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59c3f28103c64d758be47bb5d7000ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a212148cc019486495cd28728039c170",
       "IPY_MODEL_28879d805f6e43b79fda5352168847b5",
       "IPY_MODEL_ed40a43cb00047d2838792046264985c"
      ],
      "layout": "IPY_MODEL_7c8f07c597b245f38b8d7fd8b41607f9"
     }
    },
    "a212148cc019486495cd28728039c170": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edac7da1229a464e83a02b8bc68c2a8e",
      "placeholder": "​",
      "style": "IPY_MODEL_b9b617a58b2048a9b59fc40c272050bb",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "28879d805f6e43b79fda5352168847b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0364ce8f83914efd8664a1c17021b15c",
      "max": 1710671599,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd1afd1790db448f88972334e371815d",
      "value": 1710671599
     }
    },
    "ed40a43cb00047d2838792046264985c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_024da94f3c404cfe8c65bd3180475914",
      "placeholder": "​",
      "style": "IPY_MODEL_fac05d87efc84cd2952c80d8f7fb2681",
      "value": " 1.71G/1.71G [00:09&lt;00:00, 291MB/s]"
     }
    },
    "7c8f07c597b245f38b8d7fd8b41607f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edac7da1229a464e83a02b8bc68c2a8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9b617a58b2048a9b59fc40c272050bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0364ce8f83914efd8664a1c17021b15c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd1afd1790db448f88972334e371815d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "024da94f3c404cfe8c65bd3180475914": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fac05d87efc84cd2952c80d8f7fb2681": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Stable diffusion noise vector**"
   ],
   "metadata": {
    "id": "bhrK-2P89LME"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create noise vectors for each artists in https://gorgeous.adityashankar.xyz/"
   ],
   "metadata": {
    "id": "kxhRUArk9LMJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check Environment"
   ],
   "metadata": {
    "id": "E1IwInNl9LML"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Environment is colab\")\n",
    "    env = \"colab\"\n",
    "elif 'KAGGLE_URL_BASE' in os.environ:\n",
    "    env = \"kaggle\"\n",
    "    print(\"Environment is kaggle\")\n",
    "else:\n",
    "    env = \"local\"\n",
    "    print(\"Environment is local\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Up7KKC29LMN",
    "outputId": "054f3bc4-918a-4d11-ba9e-ad985e840410",
    "execution": {
     "iopub.status.busy": "2023-05-26T14:45:10.484550Z",
     "iopub.execute_input": "2023-05-26T14:45:10.484835Z",
     "iopub.status.idle": "2023-05-26T14:45:10.498458Z",
     "shell.execute_reply.started": "2023-05-26T14:45:10.484808Z",
     "shell.execute_reply": "2023-05-26T14:45:10.497448Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Environment is colab\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set ENV_TYPE\n",
    "If ENV_TYPE is equal to \"TEST\", then some examples of data will be run in order to test whether the notebooks running or not.\n",
    "Otherwise, the notebook will run on the whole dataset"
   ],
   "metadata": {
    "id": "mAa4AQ_i9LMR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ENV_TYPE=\"TEST\""
   ],
   "metadata": {
    "id": "R3YvbqIL9LMS",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if ENV_TYPE == \"TEST\":\n",
    "    model_path = \"/input/models\"\n",
    "    base_directory = \"../\"\n",
    "else:\n",
    "    # clone the repository\n",
    "    !git clone https://github.com/kk-digital/kcg-ml-sd1p4.git\n",
    "\n",
    "    # move to the repo\n",
    "    %cd kcg-ml-sd1p4/\n",
    "\n",
    "    model_path = \"./\"\n",
    "    # Get the current directory\n",
    "    base_directory = os.getcwd()\n",
    "    base_directory = os.path.join(base_directory, 'kcg-ml')\n",
    "    # download model weights\n",
    "    !wget https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\n",
    "\n",
    "# Construct the paths based on the current directory\n",
    "stable_diffusion_path = os.path.join(base_directory, 'stable_diffusion')\n",
    "\n",
    "# Insert the paths into sys.path\n",
    "sys.path.insert(0, stable_diffusion_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXfTJGsR-gtk",
    "outputId": "db845f8d-5cfd-41ef-9b8b-1497e3af4e0b",
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-05-28 08:57:35--  https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\n",
      "Resolving huggingface.co (huggingface.co)... 18.155.68.116, 18.155.68.44, 18.155.68.121, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.155.68.116|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd-v1-4.ckpt%3B+filename%3D%22sd-v1-4.ckpt%22%3B&Expires=1685519234&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRjLzM3LzRjMzcyYjRlYmI1N2JiZDAyZTY4NDEzZDQ5NTFhYTMyNmQ0YjNjZmI2ZTYyZGI5ODllNTI5YzZkNGIyNmZiMjEvZmU0ZWZmZjFlMTc0YzYyNzI1NmU0NGVjMjk5MWJhMjc5YjM4MTZlMzY0YjQ5ZjliZTJhYmMwYjNmZjNmODU1Nj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODU1MTkyMzR9fX1dfQ__&Signature=C8LOW4RHefLstwbWUv510TxOaAjN2r1ln52umz4gJOFVelJGjEmq3Jx6HDsddM004fW21HeNQCvBjRTZxuKBwoISypisFmz9pJZCQRjySCVE4L2AgIXPvSsl7T-z%7EERRDUUzCJdLlADKy6GGWIbiysT80O1sPj4r1zQzkYcf5FgxGX9nGCoXowK7awPP7xsWINRWOygrUyUxRJ8yTOPMUjWgWafrr6yIL9h53PYfHDVp-9qANdLkUWKsPBWIoeb3o8KrsWP%7Erc4gMT0odhFF%7ELNCtfKnylUq1mCNFRzeas6-QhJwC8IwDnjCFv6zeyqhxKPdNu9It7bL-cebdV-a8Q__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-05-28 08:57:35--  https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd-v1-4.ckpt%3B+filename%3D%22sd-v1-4.ckpt%22%3B&Expires=1685519234&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRjLzM3LzRjMzcyYjRlYmI1N2JiZDAyZTY4NDEzZDQ5NTFhYTMyNmQ0YjNjZmI2ZTYyZGI5ODllNTI5YzZkNGIyNmZiMjEvZmU0ZWZmZjFlMTc0YzYyNzI1NmU0NGVjMjk5MWJhMjc5YjM4MTZlMzY0YjQ5ZjliZTJhYmMwYjNmZjNmODU1Nj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODU1MTkyMzR9fX1dfQ__&Signature=C8LOW4RHefLstwbWUv510TxOaAjN2r1ln52umz4gJOFVelJGjEmq3Jx6HDsddM004fW21HeNQCvBjRTZxuKBwoISypisFmz9pJZCQRjySCVE4L2AgIXPvSsl7T-z%7EERRDUUzCJdLlADKy6GGWIbiysT80O1sPj4r1zQzkYcf5FgxGX9nGCoXowK7awPP7xsWINRWOygrUyUxRJ8yTOPMUjWgWafrr6yIL9h53PYfHDVp-9qANdLkUWKsPBWIoeb3o8KrsWP%7Erc4gMT0odhFF%7ELNCtfKnylUq1mCNFRzeas6-QhJwC8IwDnjCFv6zeyqhxKPdNu9It7bL-cebdV-a8Q__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.94, 18.155.68.128, 18.155.68.73, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.94|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4265380512 (4.0G) [binary/octet-stream]\n",
      "Saving to: ‘sd-v1-4.ckpt’\n",
      "\n",
      "sd-v1-4.ckpt        100%[===================>]   3.97G   240MB/s    in 20s     \n",
      "\n",
      "2023-05-28 08:57:56 (201 MB/s) - ‘sd-v1-4.ckpt’ saved [4265380512/4265380512]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Install the requirements**"
   ],
   "metadata": {
    "id": "IXhWMjR_KYLV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip3 install -r requirements.txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dx2VMOyMKGjd",
    "outputId": "61837d61-6e28-47ff-f4e8-505479247f9f",
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting accelerate==0.19.0 (from -r requirements.txt (line 1))\n",
      "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m219.1/219.1 kB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting diffusers==0.16.1 (from -r requirements.txt (line 2))\n",
      "  Downloading diffusers-0.16.1-py3-none-any.whl (934 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m934.9/934.9 kB\u001B[0m \u001B[31m63.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting einops==0.6.1 (from -r requirements.txt (line 3))\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.2/42.2 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Flask==2.3.2 (from -r requirements.txt (line 5))\n",
      "  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m96.9/96.9 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting ftfy==6.1.1 (from -r requirements.txt (line 6))\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.1/53.1 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting labml==0.4.162 (from -r requirements.txt (line 7))\n",
      "  Downloading labml-0.4.162-py3-none-any.whl (129 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.3/129.3 kB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting labml_nn==0.4.133 (from -r requirements.txt (line 8))\n",
      "  Downloading labml_nn-0.4.133-py3-none-any.whl (434 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m434.9/434.9 kB\u001B[0m \u001B[31m49.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting ldm==0.1.3 (from -r requirements.txt (line 9))\n",
      "  Downloading ldm-0.1.3.tar.gz (6.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting lbry-libtorrent (from -r requirements.txt (line 10))\n",
      "  Downloading lbry_libtorrent-1.2.4-py3-none-any.whl (2.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m41.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (3.7.1)\n",
      "Collecting numpy==1.24.3 (from -r requirements.txt (line 12))\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.3/17.3 MB\u001B[0m \u001B[31m86.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting omegaconf==2.3.0 (from -r requirements.txt (line 13))\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.5/79.5 kB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Pillow==9.0.0 (from -r requirements.txt (line 14))\n",
      "  Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.3/4.3 MB\u001B[0m \u001B[31m103.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pytorch_lightning (from -r requirements.txt (line 15))\n",
      "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m719.0/719.0 kB\u001B[0m \u001B[31m68.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting Requests==2.30.0 (from -r requirements.txt (line 16))\n",
      "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.5/62.5 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.10.1)\n",
      "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (4.65.0)\n",
      "Collecting transformers==4.29.2 (from -r requirements.txt (line 20))\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.1/7.1 MB\u001B[0m \u001B[31m109.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting fire (from -r requirements.txt (line 21))\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m88.3/88.3 kB\u001B[0m \u001B[31m13.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting jupyter-runner (from -r requirements.txt (line 22))\n",
      "  Downloading jupyter-runner-2022.10.26.1.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting torchtext==0.6.0 (from -r requirements.txt (line 23))\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.2/64.2 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0->-r requirements.txt (line 1)) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19.0->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1->-r requirements.txt (line 2)) (3.12.0)\n",
      "Collecting huggingface-hub>=0.13.2 (from diffusers==0.16.1->-r requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m224.5/224.5 kB\u001B[0m \u001B[31m25.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting importlib-metadata (from diffusers==0.16.1->-r requirements.txt (line 2))\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.16.1->-r requirements.txt (line 2)) (2022.10.31)\n",
      "Collecting Werkzeug>=2.3.3 (from Flask==2.3.2->-r requirements.txt (line 5))\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m242.5/242.5 kB\u001B[0m \u001B[31m29.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==2.3.2->-r requirements.txt (line 5)) (8.1.3)\n",
      "Collecting blinker>=1.6.2 (from Flask==2.3.2->-r requirements.txt (line 5))\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 6)) (0.2.6)\n",
      "Collecting gitpython (from labml==0.4.162->-r requirements.txt (line 7))\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m184.3/184.3 kB\u001B[0m \u001B[31m24.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting labml-helpers>=0.4.89 (from labml_nn==0.4.133->-r requirements.txt (line 8))\n",
      "  Downloading labml_helpers-0.4.89-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from labml_nn==0.4.133->-r requirements.txt (line 8)) (0.15.2+cu118)\n",
      "Collecting fairscale (from labml_nn==0.4.133->-r requirements.txt (line 8))\n",
      "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m266.3/266.3 kB\u001B[0m \u001B[31m35.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Installing backend dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 11)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 11)) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 11)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 11)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 11)) (2.8.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0->-r requirements.txt (line 13))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m117.0/117.0 kB\u001B[0m \u001B[31m17.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests==2.30.0->-r requirements.txt (line 16)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests==2.30.0->-r requirements.txt (line 16)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from Requests==2.30.0->-r requirements.txt (line 16)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests==2.30.0->-r requirements.txt (line 16)) (2022.12.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 18)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 18)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 18)) (3.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 18)) (2.0.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2->-r requirements.txt (line 20))\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/7.8 MB\u001B[0m \u001B[31m118.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0->-r requirements.txt (line 23)) (1.16.0)\n",
      "Collecting sentencepiece (from torchtext==0.6.0->-r requirements.txt (line 23))\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m80.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 18)) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 18)) (16.0.5)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning->-r requirements.txt (line 15)) (2023.4.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m519.2/519.2 kB\u001B[0m \u001B[31m55.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting lightning-utilities>=0.7.0 (from pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 21)) (2.3.0)\n",
      "Collecting docopt (from jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting jupyter (from jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from jupyter-runner->-r requirements.txt (line 22)) (6.3.1)\n",
      "Collecting botocore (from jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading botocore-1.29.142-py3-none-any.whl (10.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.8/10.8 MB\u001B[0m \u001B[31m111.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting boto3 (from jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading boto3-1.26.142-py3-none-any.whl (135 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m135.6/135.6 kB\u001B[0m \u001B[31m20.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m63.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask==2.3.2->-r requirements.txt (line 5)) (2.1.2)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.8/79.8 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting gitdb<5,>=4.0.1 (from gitpython->labml==0.4.162->-r requirements.txt (line 7))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.16.1->-r requirements.txt (line 2)) (3.15.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->jupyter-runner->-r requirements.txt (line 22)) (6.4.8)\n",
      "Collecting qtconsole (from jupyter->jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading qtconsole-5.4.3-py3-none-any.whl (121 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.9/121.9 kB\u001B[0m \u001B[31m13.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->jupyter-runner->-r requirements.txt (line 22)) (6.1.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->jupyter-runner->-r requirements.txt (line 22)) (6.5.4)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->jupyter-runner->-r requirements.txt (line 22)) (5.5.6)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->jupyter-runner->-r requirements.txt (line 22)) (7.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r requirements.txt (line 18)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15)) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m114.5/114.5 kB\u001B[0m \u001B[31m16.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m268.8/268.8 kB\u001B[0m \u001B[31m33.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m149.6/149.6 kB\u001B[0m \u001B[31m21.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 15))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->labml==0.4.162->-r requirements.txt (line 7))\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (5.7.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (6.1.12)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->jupyter-runner->-r requirements.txt (line 22)) (3.6.4)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->jupyter-runner->-r requirements.txt (line 22)) (3.0.7)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->jupyter-runner->-r requirements.txt (line 22)) (3.0.38)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->jupyter-runner->-r requirements.txt (line 22)) (2.14.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (4.11.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.7.4)\n",
      "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (5.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (1.2.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (23.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (21.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (1.5.6)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.16.0)\n",
      "Collecting qtpy>=2.0.1 (from qtconsole->jupyter->jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading QtPy-2.3.1-py3-none-any.whl (84 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.9/84.9 kB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (67.7.2)\n",
      "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22))\n",
      "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m94.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (4.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (3.3.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (2.16.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (4.3.3)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (2.4.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->jupyter-runner->-r requirements.txt (line 22)) (0.19.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->jupyter-runner->-r requirements.txt (line 22)) (2.21)\n",
      "Building wheels for collected packages: ldm, antlr4-python3-runtime, fire, jupyter-runner, docopt, fairscale\n",
      "  Building wheel for ldm (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for ldm: filename=ldm-0.1.3-py3-none-any.whl size=6205 sha256=074f624cd7bc7d0fca43f9ad1094dd834b3a971f1026990a7436d72c27ee57e2\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/66/44/8ac06fa0add7124672b8e7413aad60f972f2a29d8ef07678f1\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=44b83acee1176297c7c105e43c3033e2075d3b9aab803c2db85a39b5403d4121\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for fire (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=b59d6db6eceb0e24b8e08d971c93eee9784405161d1d144bc8f385ea06d8c1ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
      "  Building wheel for jupyter-runner (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for jupyter-runner: filename=jupyter_runner-2022.10.26.1-py3-none-any.whl size=13671 sha256=1820f79460cc95366a411771fc1dd2a22540983f9004e7c3c2cb924b6d152987\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/d8/e2/9e5085719ee70af881be21b24a51c84b97874608824a5e3950\n",
      "  Building wheel for docopt (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=829c22481cc73d2adcf83d84307c252273f7492dea9820f43af11e7655e4ded4\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=2166b885e1d5cdb3769b6a12cf4d232a7975b9f4ba99916c3396fec43b695ea9\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
      "Successfully built ldm antlr4-python3-runtime fire jupyter-runner docopt fairscale\n",
      "Installing collected packages: tokenizers, sentencepiece, ldm, lbry-libtorrent, docopt, antlr4-python3-runtime, Werkzeug, smmap, Requests, qtpy, Pillow, omegaconf, numpy, multidict, lightning-utilities, jmespath, jedi, importlib-metadata, ftfy, frozenlist, fire, einops, blinker, async-timeout, yarl, huggingface-hub, gitdb, Flask, botocore, aiosignal, transformers, s3transfer, gitpython, diffusers, aiohttp, qtconsole, labml, boto3, jupyter, jupyter-runner, torchtext, torchmetrics, labml-helpers, fairscale, pytorch_lightning, labml_nn, accelerate\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.3.0\n",
      "    Uninstalling Werkzeug-2.3.0:\n",
      "      Successfully uninstalled Werkzeug-2.3.0\n",
      "  Attempting uninstall: Requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "      Successfully uninstalled Pillow-8.4.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "  Attempting uninstall: Flask\n",
      "    Found existing installation: Flask 2.2.4\n",
      "    Uninstalling Flask-2.2.4:\n",
      "      Successfully uninstalled Flask-2.2.4\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.15.2\n",
      "    Uninstalling torchtext-0.15.2:\n",
      "      Successfully uninstalled torchtext-0.15.2\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.30.0 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed Flask-2.3.2 Pillow-9.0.0 Requests-2.30.0 Werkzeug-2.3.4 accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 blinker-1.6.2 boto3-1.26.142 botocore-1.29.142 diffusers-0.16.1 docopt-0.6.2 einops-0.6.1 fairscale-0.4.13 fire-0.5.0 frozenlist-1.3.3 ftfy-6.1.1 gitdb-4.0.10 gitpython-3.1.31 huggingface-hub-0.14.1 importlib-metadata-6.6.0 jedi-0.18.2 jmespath-1.0.1 jupyter-1.0.0 jupyter-runner-2022.10.26.1 labml-0.4.162 labml-helpers-0.4.89 labml_nn-0.4.133 lbry-libtorrent-1.2.4 ldm-0.1.3 lightning-utilities-0.8.0 multidict-6.0.4 numpy-1.24.3 omegaconf-2.3.0 pytorch_lightning-2.0.2 qtconsole-5.4.3 qtpy-2.3.1 s3transfer-0.6.1 sentencepiece-0.1.99 smmap-5.0.0 tokenizers-0.13.3 torchmetrics-0.11.4 torchtext-0.6.0 transformers-4.29.2 yarl-1.9.2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL",
         "numpy",
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Computing Platform Check GPU (CUDA) or CPU / Environment**\n"
   ],
   "metadata": {
    "id": "cn3FjJ4hKaV9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print ('[WARNING] CUDA/GPU is not available! Compute-intensive scripts on this notebook will be run on CPU.')\n",
    "    device =  \"cpu\""
   ],
   "metadata": {
    "id": "fT5fSvzOKd-b",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Import the Module/Utility**"
   ],
   "metadata": {
    "id": "No6FXOE-KmXj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import sys\n",
    "import importlib\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from stable_diffusion.sampler.ddim import DDIMSampler\n",
    "from stable_diffusion.sampler.ddpm import DDPMSampler\n",
    "from stable_diffusion.util import load_model, save_images, set_seed\n",
    "from stable_diffusion.model.unet_attention import CrossAttention\n",
    "from stable_diffusion.util import save_images, set_seed"
   ],
   "metadata": {
    "id": "x2rrpBScKnf8",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from stable_diffusion.latent_diffusion import LatentDiffusion\n",
    "from pathlib import Path\n",
    "\n",
    "class Txt2Img:\n",
    "    \"\"\"\n",
    "    ### Text to image class\n",
    "    \"\"\"\n",
    "    model: LatentDiffusion\n",
    "\n",
    "    def __init__(self, *,\n",
    "                 checkpoint_path: Path,\n",
    "                 sampler_name: str,\n",
    "                 n_steps: int = 50,\n",
    "                 ddim_eta: float = 0.0,\n",
    "                 force_cpu: bool = False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param checkpoint_path: is the path of the checkpoint\n",
    "        :param sampler_name: is the name of the [sampler](../sampler/index.html)\n",
    "        :param n_steps: is the number of sampling steps\n",
    "        :param ddim_eta: is the [DDIM sampling](../sampler/ddim.html) $\\eta$ constant\n",
    "        \"\"\"\n",
    "        device_id = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        if force_cpu:\n",
    "            device_id = \"cpu\"\n",
    "\n",
    "        # Load [latent diffusion model](../latent_diffusion.html)\n",
    "        self.model = load_model(checkpoint_path, device_id)\n",
    "        # Get device or force CPU if requested\n",
    "        self.device = torch.device(device_id)\n",
    "\n",
    "        # Move the model to device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Initialize [sampler](../sampler/index.html)\n",
    "        if sampler_name == 'ddim':\n",
    "            self.sampler = DDIMSampler(self.model,\n",
    "                                       n_steps=n_steps,\n",
    "                                       ddim_eta=ddim_eta)\n",
    "        elif sampler_name == 'ddpm':\n",
    "            self.sampler = DDPMSampler(self.model)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, *,\n",
    "                 seed: int = 0,\n",
    "                 dest_path: str,\n",
    "                 batch_size: int = 1,\n",
    "                 prompt: str,\n",
    "                 h: int = 512, w: int = 512,\n",
    "                 uncond_scale: float = 7.5,\n",
    "                 low_vram: bool = False,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param seed: the seed to use when generating the images\n",
    "        :param dest_path: is the path to store the generated images\n",
    "        :param batch_size: is the number of images to generate in a batch\n",
    "        :param prompt: is the prompt to generate images with\n",
    "        :param h: is the height of the image\n",
    "        :param w: is the width of the image\n",
    "        :param uncond_scale: is the unconditional guidance scale $s$. This is used for\n",
    "            $\\epsilon_\\theta(x_t, c) = s\\epsilon_\\text{cond}(x_t, c) + (s - 1)\\epsilon_\\text{cond}(x_t, c_u)$\n",
    "        :param low_vram: whether to limit VRAM usage\n",
    "        \"\"\"\n",
    "        # Number of channels in the image\n",
    "        c = 4\n",
    "        # Image to latent space resolution reduction\n",
    "        f = 8\n",
    "\n",
    "        set_seed(seed)\n",
    "        # Adjust batch size based on VRAM availability\n",
    "        if low_vram:\n",
    "            batch_size = 1\n",
    "\n",
    "        # Make a batch of prompts\n",
    "        prompts = batch_size * [prompt]\n",
    "\n",
    "        # AMP auto casting\n",
    "        cpu_or_cuda = \"cpu\" if self.device == torch.device(\"cpu\") else \"cuda\"\n",
    "        with torch.autocast(cpu_or_cuda):\n",
    "            # In unconditional scaling is not $1$ get the embeddings for empty prompts (no conditioning).\n",
    "            if uncond_scale != 1.0:\n",
    "                un_cond = self.model.get_text_conditioning(batch_size * [\"\"])\n",
    "            else:\n",
    "                un_cond = None\n",
    "            # Get the prompt embeddings\n",
    "            cond = self.model.get_text_conditioning(prompts)\n",
    "            # [Sample in the latent space](../sampler/index.html).\n",
    "            # `x` will be of shape `[batch_size, c, h / f, w / f]`\n",
    "            x = self.sampler.sample(cond=cond,\n",
    "                                    shape=[batch_size, c, h // f, w // f],\n",
    "                                    uncond_scale=uncond_scale,\n",
    "                                    uncond_cond=un_cond)\n",
    "            # Decode the image from the [autoencoder](../model/autoencoder.html)\n",
    "            images = self.model.autoencoder_decode(x)\n",
    "\n",
    "        # Save images\n",
    "        save_images(images, dest_path)\n",
    "\n",
    "    # functions for pipeline\n",
    "    @torch.no_grad()\n",
    "    def generate_text_embeddings(self,\n",
    "                                 seed,\n",
    "                                 prompt,\n",
    "                                 batch_size=4,\n",
    "                                 uncond_scale=7.5,\n",
    "                                 low_vram: bool = False,):\n",
    "        set_seed(seed)\n",
    "        # Adjust batch size based on VRAM availability\n",
    "        if low_vram:\n",
    "            batch_size = 1\n",
    "\n",
    "        # Make a batch of prompts\n",
    "        prompts = batch_size * [prompt]\n",
    "\n",
    "        # AMP auto casting\n",
    "        cpu_or_cuda = \"cpu\" if self.device == torch.device(\"cpu\") else \"cuda\"\n",
    "        with torch.autocast(cpu_or_cuda):\n",
    "            # In unconditional scaling is not $1$ get the embeddings for empty prompts (no conditioning).\n",
    "            if uncond_scale != 1.0:\n",
    "                un_cond = self.model.get_text_conditioning(batch_size * [\"\"])\n",
    "            else:\n",
    "                un_cond = None\n",
    "            # Get the prompt embeddings\n",
    "            cond = self.model.get_text_conditioning(prompts)\n",
    "        return cond, un_cond\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_latent_space(self, cond, un_cond, batch_size=4, uncond_scale=7.5, h=512, w=512):\n",
    "        # Number of channels in the image\n",
    "        c = 4\n",
    "        # Image to latent space resolution reduction\n",
    "        f = 8\n",
    "        # [Sample in the latent space](../sampler/index.html).\n",
    "        # `x` will be of shape `[batch_size, c, h / f, w / f]`\n",
    "        x = self.sampler.sample(cond=cond,\n",
    "                                shape=[batch_size, c, h // f, w // f],\n",
    "                                uncond_scale=uncond_scale,\n",
    "                                uncond_cond=un_cond)\n",
    "        # return the embeddings\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_image(self, x, dest_path):\n",
    "        # Decode the image from the [autoencoder](../model/autoencoder.html)\n",
    "        images = self.model.autoencoder_decode(x)\n",
    "\n",
    "        # Save images\n",
    "        save_images(images, dest_path)"
   ],
   "metadata": {
    "trusted": true,
    "id": "Xn6vxsPM6Cj-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Read artist list**"
   ],
   "metadata": {
    "id": "kni8zd2F5nG6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "url = \"../input/artists.txt\"\n",
    "prompt = \"A woman with flowers in her hair in a courtyard, in the style of\"\n",
    "seeds = [0, 1, 2, 3, 5, 8, 13, 21]\n",
    "file = open(url, \"r\")\n",
    "artist_list = [artist[:-1] for artist in file]\n",
    "if ENV_TYPE == \"TEST\":\n",
    "    artist_list = artist_list[0:3]\n",
    "print(artist_list[0:3])"
   ],
   "metadata": {
    "id": "F1ya3gSiK82r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0b2346d9-f04c-4f9d-8830-8be003cb75e4",
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Frank Frazetta', 'Niklas Jansson', 'androidarts']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 3 Assign integer to each artist**"
   ],
   "metadata": {
    "id": "FOD5Dsui9v2b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "artist_dict = {}\n",
    "for artist in artist_list:\n",
    "    index = artist_list.index(artist)\n",
    "    index = str(index).zfill(4)\n",
    "    artist_dict[index] = {'id': index,\n",
    "                          'name': artist\n",
    "                         }"
   ],
   "metadata": {
    "id": "Di9irCPO7HN5",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 4 generates prompt function**"
   ],
   "metadata": {
    "id": "BGfeYGla-6OL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_prompt(artist, prompt):\n",
    "    return f\"{prompt} {artist}\""
   ],
   "metadata": {
    "id": "2I0ndZze-hj2",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for artist_id in artist_dict:\n",
    "    artist_dict[artist_id]['prompt'] = generate_prompt(artist_dict[artist_id]['name'], prompt)\n",
    "print(artist_dict['0000'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mRk6Vcr9APys",
    "outputId": "67408a91-4edd-4bf6-a8ae-08e631feffd3",
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id': '0000', 'name': 'Frank Frazetta', 'prompt': 'A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 5 set noise vector**"
   ],
   "metadata": {
    "id": "ZS0Oi43sCQWo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def set_noise_vector(seed, device, height=512, factor=8, width=512):\n",
    "    set_seed(seed)\n",
    "    return torch.randn([1, 4, height // factor, width // factor], device='cpu')"
   ],
   "metadata": {
    "id": "f5jjZp5XBK-M",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 6 save n noise vector**"
   ],
   "metadata": {
    "id": "7IyVAMYA1i1j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create a list of n noise vectors name\n",
    "def create_n_vector_name(n_vector):\n",
    "    noise_vector_name = []\n",
    "    for i in range(0,n_vector):\n",
    "        name = f\"n{i:03d}\"\n",
    "        noise_vector_name.append(name)\n",
    "    return noise_vector_name"
   ],
   "metadata": {
    "id": "hfHtsK1Fz5K2",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prompt_and_seed = []\n",
    "for artist_id in artist_dict:\n",
    "    noise_vector_name = create_n_vector_name(4)\n",
    "    noise_vectors = {}    \n",
    "    for i in range(0,len(noise_vector_name)):\n",
    "        vector = set_noise_vector(seeds[i], device)\n",
    "        noise_vectors[noise_vector_name[i]] = vector\n",
    "        image_name = f\"a{artist_id}{noise_vector_name[i]}.jpg\"\n",
    "        prompt_and_seed.append([artist_dict[artist_id]['prompt'], seeds[i], image_name])\n",
    "    artist_dict[artist_id]['noise_vectors'] = noise_vectors\n",
    "    artist_dict[artist_id]['seeds'] = seeds"
   ],
   "metadata": {
    "id": "bDRVxcs72cX9",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(prompt_and_seed[0:3])"
   ],
   "metadata": {
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRn-YVhM6CkD",
    "outputId": "f64b3229-2375-4b64-d061-d3a5176ae249"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta', 0, 'a0000n000.jpg'], ['A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta', 1, 'a0000n001.jpg'], ['A woman with flowers in her hair in a courtyard, in the style of Frank Frazetta', 2, 'a0000n002.jpg']]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### save artist_dict as json"
   ],
   "metadata": {
    "id": "pVqG0JSpEX9K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "new_dict = artist_dict\n",
    "for artist in new_dict:\n",
    "    for noise_vector in new_dict[artist]['noise_vectors']:\n",
    "        if isinstance(new_dict[artist]['noise_vectors'][noise_vector], torch.Tensor):\n",
    "            new_dict[artist]['noise_vectors'][noise_vector] = new_dict[artist]['noise_vectors'][noise_vector].cpu().numpy().tolist()\n",
    "with open(\"artist_noise_vectors.json\", \"w\") as f:\n",
    "    json.dump(new_dict, f)"
   ],
   "metadata": {
    "id": "DJqUn3mVEWow",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Step 7 check that same noise vector and prompt generates the same image**"
   ],
   "metadata": {
    "id": "HrfkhanV6msl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CHECKPOINT = os.path.join(model_path, './sd-v1-4.ckpt')\n",
    "output_dir = './output/'\n",
    "sampler_name = \"ddim\"\n",
    "steps = 50"
   ],
   "metadata": {
    "id": "K4Y84Upj9OnE",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_to_image = Txt2Img(checkpoint_path=CHECKPOINT,\n",
    "                        sampler_name=sampler_name,\n",
    "                        n_steps=steps)"
   ],
   "metadata": {
    "id": "GGbv_F6pErGr",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490,
     "referenced_widgets": [
      "35bb3c45621b4fe3b3e991532d65d1b0",
      "76e42174ce1148649f569da7fdc454ef",
      "9da8a9890ae34acd85e3322cb7e1879d",
      "489eb1494d0841f5935e749061943405",
      "6ff8e29f3ce74cc4aa499b0343c33461",
      "52f9c152e30344a88e95c454b91a0e09",
      "7b9dad6af99e4af9bdee1964d8672b00",
      "4a7d01bab6164bfba8078ae217e0f601",
      "585be3ffc10b4e29a46e00e91cffa9a1",
      "ad3c6a5b16e74f9fa42658af767c5381",
      "c9f1bf9cad794c0aa1985de2ceb0b0a6",
      "1a278ebcc75b4f2fb9c44fc5616f0655",
      "65681fd618634daa9981d5fbd423f5a0",
      "3c2d584c22f14c06aaa06e542816cdea",
      "69feb2189cc444249e9ed13cbd2603f6",
      "28363e88abdb4333aefa4b76f660b69d",
      "ece614aa62b84c4eabd66efeb179ba00",
      "df34c40d2a95440d9422b25d2710367d",
      "02be864ed2fb4ce59d454e8e200f496e",
      "dd65dc920cb74cb4ae0775457d56bd4e",
      "deb11b201cbe4fde96c50448fcca96b9",
      "19dfd19815484d53b09e73158ff7657b",
      "443a0558a9534b7295548bbe69070ff6",
      "967f2c42193c499ca18d644d0598b4c7",
      "9bb488f5d9ee4c448da77e8b865ced5b",
      "aac69752985c41309025a897cc3726f0",
      "c334ed6114d5480caaef430ce31d557f",
      "914e18d4c9ec49f6bad984d89d0466d4",
      "1429f8e001c043d48ded3d57b911f39b",
      "6645620b75fa4eeeb18eaf378042a627",
      "1f2b4416f69b47f39871de6d894f47f6",
      "a727167a830f4b07b8b9e25bb5911069",
      "197f71329bae49fc857cf9fba7b966ea",
      "9bfb796975fe43c3a4ff38a43dfffa15",
      "0aaa27cb292c414fb9999ae6f3c430e0",
      "afe6358503eb49a6a68cba812c779f9d",
      "78fe3dc25b8d4d82934eb038c1f1c8c1",
      "de1a6a29cee54ecbbfb8c45d917b714d",
      "28606f18cfc64915b35fce34fa3e7802",
      "b9a23c35e15d4be8ba27704873a4acb7",
      "629a3159f2cd4d87bcd4089e97af5e55",
      "85f7ddc1b32a4982a5e7d932b8d42c7b",
      "3315216024c84e7f811e62eb75dba07f",
      "1a71866403fe4da4b93210e237d26b7e",
      "25d4e2a9fcf2431ba1341c55d2f4144d",
      "6b83beeea1244f5caa4fb129d24c223e",
      "b123a76a5926475f8009b74201ca7f45",
      "59154af5d9824f44a3dc5a25bb2ce745",
      "9b7e5d7183464f06bff392c9477c236b",
      "5f90762beb7e4b9d89508e8978aee4b8",
      "c72cc1dedd7b4c04bc151223b534c3b4",
      "e3d81a1bb9f646ed810266cbe8a4a7af",
      "59d5b5fcda0b43959b6dc4273519b5cc",
      "e6e6a5253ea84251831ad8fd46ccdd34",
      "0b62c72b52f24b418d4e8175cf081513",
      "59c3f28103c64d758be47bb5d7000ea3",
      "a212148cc019486495cd28728039c170",
      "28879d805f6e43b79fda5352168847b5",
      "ed40a43cb00047d2838792046264985c",
      "7c8f07c597b245f38b8d7fd8b41607f9",
      "edac7da1229a464e83a02b8bc68c2a8e",
      "b9b617a58b2048a9b59fc40c272050bb",
      "0364ce8f83914efd8664a1c17021b15c",
      "cd1afd1790db448f88972334e371815d",
      "024da94f3c404cfe8c65bd3180475914",
      "fac05d87efc84cd2952c80d8f7fb2681"
     ]
    },
    "outputId": "5eb24993-068b-4d7e-e655-cf5b80a736d7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Initialize autoencoder<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t834.01ms</span>\n",
       "Initialize CLIP Embedder<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t16,329.95ms</span>\n",
       "Initialize U-Net<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t9,562.52ms</span>\n",
       "Initialize Latent Diffusion model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t18.38ms</span>\n",
       "Loading model from ./sd-v1-4.ckpt<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t19,224.47ms</span>\n",
       "Load state<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t788.66ms</span>\n",
       "<span style=\"text-decoration: underline\">global_step</span>\n",
       "470000\n",
       "<span style=\"text-decoration: underline\">missing_keys</span>\n",
       "['beta', 'alpha_bar']\n",
       "<span style=\"text-decoration: underline\">extra_keys</span>\n",
       "['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2', 'model_ema.decay', 'model_ema.num_updates']</pre>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35bb3c45621b4fe3b3e991532d65d1b0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a278ebcc75b4f2fb9c44fc5616f0655"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "443a0558a9534b7295548bbe69070ff6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bfb796975fe43c3a4ff38a43dfffa15"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25d4e2a9fcf2431ba1341c55d2f4144d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59c3f28103c64d758be47bb5d7000ea3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'text_projection.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'logit_scale', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"number of images being generate: {len(prompt_and_seed)}\")\n",
    "start_point = time.time()\n",
    "for prompt, seed, image_name in prompt_and_seed:\n",
    "    start_time = time.time()\n",
    "    image_path = os.path.join(output_dir, image_name)\n",
    "    cond, un_cond = text_to_image.generate_text_embeddings(seed, prompt)\n",
    "    latent_space = text_to_image.generate_latent_space(cond, un_cond)\n",
    "    text_to_image.generate_image(latent_space, image_path)\n",
    "    print(f\"time to generate image number {prompt_and_seed.index([prompt, seed, image_name])} as {image_path} is: {time.time()- start_time}\")\n",
    "print(f\"total run time is: {time.time() - start_point}\")"
   ],
   "metadata": {
    "id": "6tIs5gT19LMf",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "faabd76c-5c9f-43c1-eec0-7da1950130b5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of images being generate: 12\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Sample<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t121,329.03ms</span>\n",
       "Sample<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t122,660.58ms</span>\n",
       "Sample<span style=\"color: #D160C4\">   86%</span><span style=\"color: #208FFB\">\t123,319.96ms</span></pre>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time to generate image number 0 as ./output/a0000n000.jpg is: 126.20038080215454\n",
      "time to generate image number 1 as ./output/a0000n001.jpg is: 124.9128692150116\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n",
       "\u001B[31m│\u001B[0m in \u001B[92m<cell line: 3>\u001B[0m:\u001B[94m7\u001B[0m                                                                              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001B[0m\u001B[1;33m_contextlib.py\u001B[0m:\u001B[94m115\u001B[0m in \u001B[92mdecorate_context\u001B[0m       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m112 \u001B[0m\u001B[2m│   \u001B[0m\u001B[1;95m@functools\u001B[0m.wraps(func)                                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m113 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mdecorate_context\u001B[0m(*args, **kwargs):                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m114 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mwith\u001B[0m ctx_factory():                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m115 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m func(*args, **kwargs)                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m116 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m117 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mreturn\u001B[0m decorate_context                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m118 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m in \u001B[92mgenerate_latent_space\u001B[0m:\u001B[94m136\u001B[0m                                                                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001B[0m\u001B[1;33m_contextlib.py\u001B[0m:\u001B[94m115\u001B[0m in \u001B[92mdecorate_context\u001B[0m       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m112 \u001B[0m\u001B[2m│   \u001B[0m\u001B[1;95m@functools\u001B[0m.wraps(func)                                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m113 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mdecorate_context\u001B[0m(*args, **kwargs):                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m114 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mwith\u001B[0m ctx_factory():                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m115 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m func(*args, **kwargs)                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m116 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m117 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mreturn\u001B[0m decorate_context                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m118 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/sampler/\u001B[0m\u001B[1;33mddim.py\u001B[0m:\u001B[94m141\u001B[0m in \u001B[92msample\u001B[0m                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m138 \u001B[0m\u001B[2m│   │   │   \u001B[0mts = x.new_full((bs,), step, dtype=torch.long)                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m139 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m140 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Sample $x_{\\tau_{i-1}}$\u001B[0m                                                      \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m141 \u001B[2m│   │   │   \u001B[0mx, pred_x0, e_t = \u001B[96mself\u001B[0m.p_sample(x, cond, ts, step, index=index,                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m142 \u001B[0m\u001B[2m│   │   │   │   │   │   │   │   │   │   │   \u001B[0mrepeat_noise=repeat_noise,                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m143 \u001B[0m\u001B[2m│   │   │   │   │   │   │   │   │   │   │   \u001B[0mtemperature=temperature,                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m144 \u001B[0m\u001B[2m│   │   │   │   │   │   │   │   │   │   │   \u001B[0muncond_scale=uncond_scale,                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/\u001B[0m\u001B[1;33m_contextlib.py\u001B[0m:\u001B[94m115\u001B[0m in \u001B[92mdecorate_context\u001B[0m       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m112 \u001B[0m\u001B[2m│   \u001B[0m\u001B[1;95m@functools\u001B[0m.wraps(func)                                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m113 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mdecorate_context\u001B[0m(*args, **kwargs):                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m114 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mwith\u001B[0m ctx_factory():                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m115 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m func(*args, **kwargs)                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m116 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m117 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mreturn\u001B[0m decorate_context                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m118 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/sampler/\u001B[0m\u001B[1;33mddim.py\u001B[0m:\u001B[94m172\u001B[0m in \u001B[92mp_sample\u001B[0m                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m169 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m170 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m171 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Get $\\epsilon_\\theta(x_{\\tau_i})$\u001B[0m                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m172 \u001B[2m│   │   \u001B[0me_t = \u001B[96mself\u001B[0m.get_eps(x, t, c,                                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m173 \u001B[0m\u001B[2m│   │   │   │   │   │      \u001B[0muncond_scale=uncond_scale,                                      \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m174 \u001B[0m\u001B[2m│   │   │   │   │   │      \u001B[0muncond_cond=uncond_cond)                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m175 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/sampler/\u001B[0m\u001B[1;33m__init__.py\u001B[0m:\u001B[94m64\u001B[0m in \u001B[92mget_eps\u001B[0m                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 61 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Concatenated $c$ and $c_u$\u001B[0m                                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 62 \u001B[0m\u001B[2m│   │   \u001B[0mc_in = torch.cat([uncond_cond, c])                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 63 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Get $\\epsilon_\\text{cond}(x_t, c)$ and $\\epsilon_\\text{cond}(x_t, c_u)$\u001B[0m          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 64 \u001B[2m│   │   \u001B[0me_t_uncond, e_t_cond = \u001B[96mself\u001B[0m.model(x_in, t_in, c_in).chunk(\u001B[94m2\u001B[0m)                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 65 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Calculate\u001B[0m                                                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 66 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# $$\\epsilon_\\theta(x_t, c) = s\\epsilon_\\text{cond}(x_t, c) + (s - 1)\\epsilon_\\t\u001B[0m   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 67 \u001B[0m\u001B[2m│   │   \u001B[0me_t = e_t_uncond + uncond_scale * (e_t_cond - e_t_uncond)                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/\u001B[0m\u001B[1;33mlatent_diffusion.py\u001B[0m:\u001B[94m145\u001B[0m in \u001B[92mforward\u001B[0m                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m142 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m143 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m$$\\epsilon_\\text{cond}(x_t, c)$$\u001B[0m                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m144 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m145 \u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.model(x, t, context)                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m146 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/\u001B[0m\u001B[1;33mlatent_diffusion.py\u001B[0m:\u001B[94m47\u001B[0m in \u001B[92mforward\u001B[0m                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 44 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m.diffusion_model = diffusion_model                                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 45 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 46 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mforward\u001B[0m(\u001B[96mself\u001B[0m, x: torch.Tensor, time_steps: torch.Tensor, context: torch.Tensor):   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 47 \u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.diffusion_model(x, time_steps, context)                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 48 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 49 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 50 \u001B[0m\u001B[94mclass\u001B[0m \u001B[4;92mLatentDiffusion\u001B[0m(nn.Module):                                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/model/\u001B[0m\u001B[1;33munet.py\u001B[0m:\u001B[94m177\u001B[0m in \u001B[92mforward\u001B[0m                              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m174 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Output half of the U-Net\u001B[0m                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m175 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m module \u001B[95min\u001B[0m \u001B[96mself\u001B[0m.output_blocks:                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m176 \u001B[0m\u001B[2m│   │   │   \u001B[0mx = torch.cat([x, x_input_block.pop()], dim=\u001B[94m1\u001B[0m)                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m177 \u001B[2m│   │   │   \u001B[0mx = module(x, t_emb, cond)                                                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m178 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m179 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Final normalization and $3 \\times 3$ convolution\u001B[0m                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m180 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.out(x)                                                                 \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/model/\u001B[0m\u001B[1;33munet.py\u001B[0m:\u001B[94m196\u001B[0m in \u001B[92mforward\u001B[0m                              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m193 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96misinstance\u001B[0m(layer, ResBlock):                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m194 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mx = layer(x, t_emb)                                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m195 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melif\u001B[0m \u001B[96misinstance\u001B[0m(layer, SpatialTransformer):                                    \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m196 \u001B[2m│   │   │   │   \u001B[0mx = layer(x, cond)                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m197 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m198 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mx = layer(x)                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m199 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m x                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/model/\u001B[0m\u001B[1;33munet_attention.py\u001B[0m:\u001B[94m70\u001B[0m in \u001B[92mforward\u001B[0m                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 67 \u001B[0m\u001B[2m│   │   \u001B[0mx = x.permute(\u001B[94m0\u001B[0m, \u001B[94m2\u001B[0m, \u001B[94m3\u001B[0m, \u001B[94m1\u001B[0m).view(b, h * w, c)                                        \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 68 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Apply the transformer layers\u001B[0m                                                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 69 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m block \u001B[95min\u001B[0m \u001B[96mself\u001B[0m.transformer_blocks:                                              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 70 \u001B[2m│   │   │   \u001B[0mx = block(x, cond)                                                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 71 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Reshape and transpose from `[batch_size, height * width, channels]`\u001B[0m              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 72 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# to `[batch_size, channels, height, width]`\u001B[0m                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m 73 \u001B[0m\u001B[2m│   │   \u001B[0mx = x.view(b, h, w, c).permute(\u001B[94m0\u001B[0m, \u001B[94m3\u001B[0m, \u001B[94m1\u001B[0m, \u001B[94m2\u001B[0m)                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/model/\u001B[0m\u001B[1;33munet_attention.py\u001B[0m:\u001B[94m109\u001B[0m in \u001B[92mforward\u001B[0m                    \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m106 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m:param cond: is the conditional embeddings of shape `[batch_size,  n_cond, d_con\u001B[0m   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m107 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m108 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Self attention\u001B[0m                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m109 \u001B[2m│   │   \u001B[0mx = \u001B[96mself\u001B[0m.attn1(\u001B[96mself\u001B[0m.norm1(x)) + x                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m110 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Cross-attention with conditioning\u001B[0m                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m111 \u001B[0m\u001B[2m│   │   \u001B[0mx = \u001B[96mself\u001B[0m.attn2(\u001B[96mself\u001B[0m.norm2(x), cond=cond) + x                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m112 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Feed-forward network\u001B[0m                                                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/model/\u001B[0m\u001B[1;33munet_attention.py\u001B[0m:\u001B[94m190\u001B[0m in \u001B[92mforward\u001B[0m                    \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m187 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.flash_attention(q, k, v)                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m188 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Otherwise, fallback to normal attention\u001B[0m                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m189 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                              \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m190 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m.normal_attention(q, k, v)                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m191 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m192 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mflash_attention\u001B[0m(\u001B[96mself\u001B[0m, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor):          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m193 \u001B[0m\u001B[2;90m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[2;33m/content/kcg-ml-sd1p4/stable_diffusion/model/\u001B[0m\u001B[1;33munet_attention.py\u001B[0m:\u001B[94m252\u001B[0m in \u001B[92mnormal_attention\u001B[0m           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m249 \u001B[0m\u001B[2m│   │   \u001B[0mv = v.view(*v.shape[:\u001B[94m2\u001B[0m], \u001B[96mself\u001B[0m.n_heads, -\u001B[94m1\u001B[0m)                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m250 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m251 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Calculate attention $\\frac{Q K^\\top}{\\sqrt{d_{key}}}$\u001B[0m                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m252 \u001B[2m│   │   \u001B[0mattn = torch.einsum(\u001B[33m'\u001B[0m\u001B[33mbihd,bjhd->bhij\u001B[0m\u001B[33m'\u001B[0m, q, k) * \u001B[96mself\u001B[0m.scale                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m253 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m254 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Compute softmax\u001B[0m                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m255 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# $$\\underset{seq}{softmax}\\Bigg(\\frac{Q K^\\top}{\\sqrt{d_{key}}}\\Bigg)$$\u001B[0m           \u001B[31m│\u001B[0m\n",
       "\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mOutOfMemoryError: \u001B[0mCUDA out of memory. Tried to allocate \u001B[1;36m4.00\u001B[0m GiB \u001B[1m(\u001B[0mGPU \u001B[1;36m0\u001B[0m; \u001B[1;36m14.75\u001B[0m GiB total capacity; \u001B[1;36m8.35\u001B[0m GiB already\n",
       "allocated; \u001B[1;36m888.81\u001B[0m MiB free; \u001B[1;36m12.59\u001B[0m GiB reserved in total by PyTorch\u001B[1m)\u001B[0m If reserved memory is >> allocated memory try \n",
       "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate_latent_space</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">136</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/sampler/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ddim.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">141</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sample</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   │   </span>ts = x.new_full((bs,), step, dtype=torch.long)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   │   │   # Sample $x_{\\tau_{i-1}}$</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>141 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x, pred_x0, e_t = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.p_sample(x, cond, ts, step, index=index,                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   │   │   │   │   │   │   │   │   │   │   </span>repeat_noise=repeat_noise,                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   │   │   │   │   │   │   │   │   │   </span>temperature=temperature,                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   │   │   │   │   │   │   │   │   │   │   </span>uncond_scale=uncond_scale,                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/sampler/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ddim.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">172</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">p_sample</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171 │   │   # Get $\\epsilon_\\theta(x_{\\tau_i})$</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>172 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>e_t = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_eps(x, t, c,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 │   │   │   │   │   │      </span>uncond_scale=uncond_scale,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   │   │   │   │      </span>uncond_cond=uncond_cond)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/sampler/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">64</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_eps</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 │   │   # Concatenated $c$ and $c_u$</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 │   │   </span>c_in = torch.cat([uncond_cond, c])                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   │   # Get $\\epsilon_\\text{cond}(x_t, c)$ and $\\epsilon_\\text{cond}(x_t, c_u)$</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 64 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>e_t_uncond, e_t_cond = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(x_in, t_in, c_in).chunk(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   │   # Calculate</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 │   │   # $$\\epsilon_\\theta(x_t, c) = s\\epsilon_\\text{cond}(x_t, c) + (s - 1)\\epsilon_\\t</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 │   │   </span>e_t = e_t_uncond + uncond_scale * (e_t_cond - e_t_uncond)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">latent_diffusion.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">$$\\epsilon_\\text{cond}(x_t, c)$$</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(x, t, context)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">latent_diffusion.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">47</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.diffusion_model = diffusion_model                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x: torch.Tensor, time_steps: torch.Tensor, context: torch.Tensor):   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 47 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.diffusion_model(x, time_steps, context)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 48 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">LatentDiffusion</span>(nn.Module):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">177</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 │   │   # Output half of the U-Net</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">175 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output_blocks:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 │   │   │   </span>x = torch.cat([x, x_input_block.pop()], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>177 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x = module(x, t_emb, cond)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 │   │   # Final normalization and $3 \\times 3$ convolution</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.out(x)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">196</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(layer, ResBlock):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 │   │   │   │   </span>x = layer(x, t_emb)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(layer, SpatialTransformer):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>196 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>x = layer(x, cond)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   │   │   │   </span>x = layer(x)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> x                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 │   │   </span>x = x.permute(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>).view(b, h * w, c)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 │   │   # Apply the transformer layers</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> block <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer_blocks:                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x = block(x, cond)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 │   │   # Reshape and transpose from `[batch_size, height * width, channels]`</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 │   │   # to `[batch_size, channels, height, width]`</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 │   │   </span>x = x.view(b, h, w, c).permute(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">109</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:param cond: is the conditional embeddings of shape `[batch_size,  n_cond, d_con</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 │   │   # Self attention</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>109 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn1(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm1(x)) + x                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   # Cross-attention with conditioning</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn2(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm2(x), cond=cond) + x                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   │   # Feed-forward network</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">190</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.flash_attention(q, k, v)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 │   │   # Otherwise, fallback to normal attention</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>190 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.normal_attention(q, k, v)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">flash_attention</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor):          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/content/kcg-ml-sd1p4/stable_diffusion/model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">unet_attention.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">252</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">normal_attention</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 │   │   </span>v = v.view(*v.shape[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.n_heads, -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">250 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">251 │   │   # Calculate attention $\\frac{Q K^\\top}{\\sqrt{d_{key}}}$</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>252 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn = torch.einsum(<span style=\"color: #808000; text-decoration-color: #808000\">'bihd,bjhd-&gt;bhij'</span>, q, k) * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scale                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">253 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254 │   │   # Compute softmax</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255 │   │   # $$\\underset{seq}{softmax}\\Bigg(\\frac{Q K^\\top}{\\sqrt{d_{key}}}\\Bigg)$$</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.00</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.35</span> GiB already\n",
       "allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">888.81</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.59</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory try \n",
       "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "3MJedlUdlLR8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
