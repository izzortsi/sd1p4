{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K0VhErRSyZVf"
      },
      "outputs": [],
      "source": [
        "# Default env type is test\n",
        "# Change this when running on colab or kaggle\n",
        "ENV_TYPE = \"TEST\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7lxOmpuP1xH"
      },
      "outputs": [],
      "source": [
        "# Important deps\n",
        "!apt update && apt install -y libgl1-mesa-glx imagemagick\n",
        "\n",
        "if ENV_TYPE != \"TEST\":\n",
        "    !apt install -y git aria2\n",
        "    # Clone the repo\n",
        "    !git clone https://github.com/kk-digital/kcg-ml-sd1p4.git --recurse-submodules -b lora\n",
        "    %cd kcg-ml-sd1p4\n",
        "    # Download model weights\n",
        "    !aria2c https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt -o ./input/model/sd-v1-4.ckpt -j 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZgfLQlHyd8n"
      },
      "outputs": [],
      "source": [
        "# Install reqs\n",
        "!pip3 install -r lora_tuning/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCEDITmRzMc1"
      },
      "outputs": [],
      "source": [
        "# Let's now run the 'test suite'\n",
        "!pip3 install accelerate==0.19.0\n",
        "!git pull\n",
        "if ENV_TYPE != \"TEST\":\n",
        "    !python3 lora_tuning/lora_train.py --num_repeats 1 --lowram True\n",
        "else:\n",
        "    !python3 lora_tuning/lora_train.py --num_repeats 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsd-2fsX0W7G"
      },
      "outputs": [],
      "source": [
        "# Shuffle up dependencies to fix inference\n",
        "!pip3 install -r lora_tuning/inference/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0leC51krVbTv"
      },
      "outputs": [],
      "source": [
        "# Generate images for each epoch:\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Set the directory containing the .safetensors files\n",
        "lora_path = \"./output/LoRa/Test/output/\"\n",
        "checkpoint_path = \"input/model/sd-v1-4.ckpt\"\n",
        "scale = 512\n",
        "prompt = \"a sketch of a pixwaifu, cute, small, chibi, DeviantArt trending\"\n",
        "\n",
        "# Get a list of all .safetensors files in the directory\n",
        "file_list = [filename for filename in os.listdir(lora_path) if filename.endswith(\".safetensors\")]\n",
        "\n",
        "# Set up epoch to begin counting\n",
        "epoch = 1\n",
        "\n",
        "for filename in file_list:\n",
        "    # Generate the image using txt2img.py for each .safetensors file\n",
        "    output_filename = os.path.splitext(filename)[0] + \".png\"\n",
        "    command = f\"python3 lora_tuning/inference/txt2img.py --checkpoint_path {checkpoint_path} --lora {os.path.join(lora_path, filename)} --output {output_filename} --scale {scale} --prompt \\\"{prompt}\\\"\"\n",
        "    !{command}\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "# Generate a tiled image with all of the epochs\n",
        "!montage -label '%t' *.png -thumbnail 512x512! -pointsize 22 -gravity center \\\n",
        "    -background Transparent -geometry +0+0 -tile 3x results_lora_epochs.png"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
